# -*- coding: utf-8 -*-
"""End_To_End_Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y15nd2MB2aKVw0VzBndgWys7e8CxTZtU
"""

"""
Complete End-to-End ControlNet Pipeline
Train, Evaluate, and Visualize with One Script
"""

import os
import sys
import argparse
import pickle
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import gdown  # For downloading from Google Drive

# ============================================================================
# CONFIGURATION
# ============================================================================

class PipelineConfig:
    """Master configuration for entire pipeline"""

    def __init__(self):
        # Data
        self.google_drive_url = "https://drive.google.com/uc?id=1FXqnuUoebvz4FYTFoZGjJGmOAC4uAQ_b"
        self.data_path = "./coco_pose_dataset.pkl"

        # Training
        self.pretrained_model = "runwayml/stable-diffusion-v1-5"
        self.num_epochs = 3
        self.train_batch_size = 4
        self.learning_rate = 1e-5
        self.resolution = 512

        # Ablation
        self.run_ablations = True
        self.ablation_experiments = [
            'lr_1e-05', 'lr_1e-04', 'lr_2e-06',
            'epochs_1', 'epochs_3',
            'scale_0.5', 'scale_1.0', 'scale_1.5'
        ]

        # Evaluation
        self.num_eval_samples = 50
        self.generate_qualitative = True

        # Output
        self.output_dir = "./controlnet_project_output"
        self.save_checkpoints = True

# ============================================================================
# DATA LOADER
# ============================================================================

def download_dataset(url, output_path):
    """Download dataset from Google Drive"""
    if os.path.exists(output_path):
        print(f"‚úì Dataset already exists at {output_path}")
        return True

    print(f"Downloading dataset from Google Drive...")
    try:
        gdown.download(url, output_path, quiet=False, fuzzy=True)
        print(f"‚úì Dataset downloaded to {output_path}")
        return True
    except Exception as e:
        print(f"‚ùå Failed to download dataset: {e}")
        print("\nAlternative: Manually download from:")
        print("https://drive.google.com/drive/folders/1uOpYTO7MJvOcGhVHUsXLjzxbpIEsJzn-")
        return False

def load_and_inspect_dataset(pkl_path):
    """Load dataset and print statistics"""
    print(f"\nLoading dataset from {pkl_path}...")

    with open(pkl_path, 'rb') as f:
        data = pickle.load(f)

    print(f"‚úì Loaded {len(data)} samples")

    # Print sample info
    sample = data[0]
    print(f"\nSample structure:")
    print(f"  - image_id: {sample['image_id']}")
    print(f"  - img shape: {sample['img'].shape}")
    print(f"  - skeleton shape: {sample['skeleton'].shape}")
    print(f"  - text_prompt: {sample['text_prompt'][:50]}...")

    # Visualize a sample
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    axes[0].imshow(sample['img'])
    axes[0].set_title('Original Image')
    axes[0].axis('off')

    axes[1].imshow(sample['skeleton'])
    axes[1].set_title('Pose Skeleton (Control Signal)')
    axes[1].axis('off')

    plt.suptitle(f"Prompt: {sample['text_prompt']}", fontsize=10)
    plt.tight_layout()

    os.makedirs('./dataset_inspection', exist_ok=True)
    plt.savefig('./dataset_inspection/sample_visualization.png', dpi=150)
    plt.close()
    print("‚úì Sample visualization saved to ./dataset_inspection/sample_visualization.png")

    return data

# ============================================================================
# TRAINING PHASE
# ============================================================================

def run_training(config):
    """Run main training"""
    print("\n" + "="*80)
    print("PHASE 1: MAIN TRAINING")
    print("="*80 + "\n")

    from controlnet_training import TrainingConfig, train_controlnet

    # Setup training config
    train_config = TrainingConfig()
    train_config.num_epochs = config.num_epochs
    train_config.train_batch_size = config.train_batch_size
    train_config.learning_rate = config.learning_rate
    train_config.resolution = config.resolution
    train_config.output_dir = os.path.join(config.output_dir, "main_training")

    # Run training
    monitor = train_controlnet(train_config, config.data_path)

    print("\n‚úì Main training complete")
    print(f"‚úì Model saved to {train_config.output_dir}/final_model")

    return train_config.output_dir

# ============================================================================
# ABLATION PHASE
# ============================================================================

def run_ablations(config):
    """Run ablation studies"""
    if not config.run_ablations:
        print("\n‚äò Skipping ablation studies (disabled in config)")
        return None

    print("\n" + "="*80)
    print("PHASE 2: ABLATION STUDIES")
    print("="*80 + "\n")

    from controlnet_training import TrainingConfig
    from ablation_study import AblationRunner, AblationSuite

    # Setup base config
    base_config = TrainingConfig()
    base_config.num_epochs = 2  # Shorter for ablations
    base_config.train_batch_size = config.train_batch_size
    base_config.resolution = config.resolution

    # Create runner
    ablation_output = os.path.join(config.output_dir, "ablations")
    runner = AblationRunner(base_config, config.data_path, ablation_output)

    # Get experiments
    all_experiments = AblationSuite.get_all_experiments()

    # Filter to selected experiments
    if config.ablation_experiments:
        experiments = [
            exp for exp in all_experiments
            if exp.name in config.ablation_experiments
        ]
    else:
        experiments = all_experiments[:5]  # Run first 5 if not specified

    print(f"Running {len(experiments)} ablation experiments...")

    # Run ablations
    runner.run_all_experiments(experiments)

    print("\n‚úì Ablation studies complete")
    print(f"‚úì Results saved to {ablation_output}")

    return ablation_output

# ============================================================================
# EVALUATION PHASE
# ============================================================================

def run_evaluation(config, model_path):
    """Run comprehensive evaluation"""
    print("\n" + "="*80)
    print("PHASE 3: EVALUATION")
    print("="*80 + "\n")

    from evaluation_viz import ComprehensiveEvaluator, FailureAnalyzer
    from diffusers import StableDiffusionControlNetPipeline, ControlNetModel

    # Load dataset for evaluation
    with open(config.data_path, 'rb') as f:
        data = pickle.load(f)

    # Take subset for evaluation
    eval_data = data[-config.num_eval_samples:]

    print(f"Evaluating on {len(eval_data)} samples...")

    # Load model
    try:
        controlnet = ControlNetModel.from_pretrained(
            os.path.join(model_path, "final_model")
        )

        pipe = StableDiffusionControlNetPipeline.from_pretrained(
            config.pretrained_model,
            controlnet=controlnet,
            torch_dtype=torch.float16
        )

        if torch.cuda.is_available():
            pipe = pipe.to("cuda")
            print("‚úì Using CUDA")
        else:
            print("‚ö†Ô∏è  CUDA not available, using CPU (slow)")

        print("‚úì Pipeline loaded")

    except Exception as e:
        print(f"‚ùå Failed to load model: {e}")
        return None

    # Generate samples
    eval_output = os.path.join(config.output_dir, "evaluation")
    os.makedirs(eval_output, exist_ok=True)

    conditioning_images = []
    generated_images = []
    ground_truth_images = []
    prompts = []

    print("\nGenerating samples for evaluation...")
    for i, sample in enumerate(eval_data[:10]):  # Generate 10 for detailed analysis
        print(f"  Sample {i+1}/10...")

        # Prepare conditioning image
        cond_img = Image.fromarray(sample['skeleton']).convert('RGB')
        cond_img = cond_img.resize((config.resolution, config.resolution))

        # Generate
        with torch.no_grad():
            output = pipe(
                sample['text_prompt'],
                image=cond_img,
                num_inference_steps=50,
                guidance_scale=7.5
            )

        gen_img = output.images[0]

        # Ground truth
        gt_img = Image.fromarray(sample['img']).convert('RGB')
        gt_img = gt_img.resize((config.resolution, config.resolution))

        conditioning_images.append(cond_img)
        generated_images.append(gen_img)
        ground_truth_images.append(gt_img)
        prompts.append(sample['text_prompt'])

        # Save individual result
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        axes[0].imshow(cond_img)
        axes[0].set_title('Conditioning (Pose)')
        axes[0].axis('off')

        axes[1].imshow(gen_img)
        axes[1].set_title('Generated')
        axes[1].axis('off')

        axes[2].imshow(gt_img)
        axes[2].set_title('Ground Truth')
        axes[2].axis('off')

        plt.suptitle(f"Prompt: {sample['text_prompt'][:60]}...", fontsize=9)
        plt.tight_layout()
        plt.savefig(os.path.join(eval_output, f'sample_{i:03d}.png'), dpi=150)
        plt.close()

    print("‚úì Samples generated")

    # Run metrics evaluation
    evaluator = ComprehensiveEvaluator(eval_output)
    results = evaluator.evaluate_batch(
        conditioning_images,
        generated_images,
        ground_truth_images,
        prompts
    )

    # Visualize results
    evaluator.visualize_results()
    evaluator.save_results()

    # Failure analysis
    analyzer = FailureAnalyzer(evaluator.results)
    analyzer.identify_failures()
    analyzer.generate_failure_report(os.path.join(eval_output, 'failure_report.json'))

    print("\n‚úì Evaluation complete")
    print(f"‚úì Results saved to {eval_output}")

    # Print summary
    print("\n" + "="*80)
    print("EVALUATION SUMMARY")
    print("="*80)
    for metric, stats in evaluator.aggregate_stats.items():
        print(f"\n{metric.upper()}:")
        print(f"  Mean: {stats['mean']:.4f}")
        print(f"  Std:  {stats['std']:.4f}")
        print(f"  Min:  {stats['min']:.4f}")
        print(f"  Max:  {stats['max']:.4f}")

    return eval_output

# ============================================================================
# REPORT GENERATION
# ============================================================================

def generate_final_report(config, training_dir, ablation_dir, eval_dir):
    """Generate final comprehensive report"""
    print("\n" + "="*80)
    print("GENERATING FINAL REPORT")
    print("="*80 + "\n")

    report_dir = os.path.join(config.output_dir, "final_report")
    os.makedirs(report_dir, exist_ok=True)

    # Collect all results
    report_content = {
        'project': 'ControlNet for Pose-to-Person Generation',
        'configuration': {
            'model': config.pretrained_model,
            'epochs': config.num_epochs,
            'batch_size': config.train_batch_size,
            'learning_rate': config.learning_rate,
            'resolution': config.resolution
        },
        'training_directory': training_dir,
        'ablation_directory': ablation_dir,
        'evaluation_directory': eval_dir
    }

    # Save report
    import json
    report_path = os.path.join(report_dir, 'project_report.json')
    with open(report_path, 'w') as f:
        json.dump(report_content, f, indent=2)

    # Create summary markdown
    md_content = f"""# ControlNet Project: Pose-to-Person Generation

## Project Overview
This project implements a ControlNet for generating person images from pose skeletons.

## Configuration
- **Base Model**: {config.pretrained_model}
- **Training Epochs**: {config.num_epochs}
- **Batch Size**: {config.train_batch_size}
- **Learning Rate**: {config.learning_rate}
- **Resolution**: {config.resolution}

## Results Structure

### 1. Training Results
Location: `{training_dir}`
- Final trained model
- Training curves
- Training logs and reports

### 2. Ablation Studies
Location: `{ablation_dir}`
- Multiple experiment configurations
- Comparative analysis
- Ablation visualizations

### 3. Evaluation Results
Location: `{eval_dir}`
- Quantitative metrics (SSIM, LPIPS, PSNR)
- Qualitative samples
- Failure analysis

## Key Files
- `training_curves.png` - Training loss over time
- `evaluation_results.json` - Detailed metrics
- `ablation_results.json` - Ablation study results
- `failure_report.json` - Analysis of failure cases

## Next Steps
1. Review evaluation metrics in `evaluation_results.json`
2. Examine ablation comparisons in `ablation_results.json`
3. Analyze failure cases for improvements
4. Fine-tune based on insights

---
Generated: {config.output_dir}
"""

    md_path = os.path.join(report_dir, 'README.md')
    with open(md_path, 'w') as f:
        f.write(md_content)

    print(f"‚úì Final report generated at {report_dir}")
    print(f"‚úì Summary: {md_path}")

    return report_dir

# ============================================================================
# MAIN PIPELINE
# ============================================================================

def main():
    """Main execution pipeline"""

    print("\n" + "="*80)
    print("CONTROLNET PROJECT: COMPLETE PIPELINE")
    print("Pose-to-Person Image Generation")
    print("="*80 + "\n")

    # Initialize configuration
    config = PipelineConfig()
    os.makedirs(config.output_dir, exist_ok=True)

    # Phase 0: Download and inspect dataset
    print("PHASE 0: DATASET PREPARATION")
    print("-" * 80)

    if not os.path.exists(config.data_path):
        success = download_dataset(config.google_drive_url, config.data_path)
        if not success:
            print("\n‚ùå Cannot proceed without dataset")
            return

    data = load_and_inspect_dataset(config.data_path)

    # Phase 1: Main Training
    training_dir = run_training(config)

    # Phase 2: Ablation Studies
    ablation_dir = run_ablations(config)

    # Phase 3: Evaluation
    eval_dir = run_evaluation(config, training_dir)

    # Phase 4: Generate Final Report
    if eval_dir:
        report_dir = generate_final_report(
            config, training_dir, ablation_dir, eval_dir
        )

    # Final summary
    print("\n" + "="*80)
    print("PIPELINE COMPLETE!")
    print("="*80)
    print(f"\n‚úì All outputs saved to: {config.output_dir}")
    print("\nDirectory structure:")
    print(f"  ‚îú‚îÄ‚îÄ main_training/       (trained model and logs)")
    print(f"  ‚îú‚îÄ‚îÄ ablations/          (ablation study results)")
    print(f"  ‚îú‚îÄ‚îÄ evaluation/         (metrics and samples)")
    print(f"  ‚îî‚îÄ‚îÄ final_report/       (comprehensive summary)")
    print("\nüéâ Project complete! Review the results and generate your report.")

if __name__ == "__main__":
    # Parse command line arguments (optional)
    parser = argparse.ArgumentParser(description='ControlNet Training Pipeline')
    parser.add_argument('--skip-ablations', action='store_true',
                       help='Skip ablation studies')
    parser.add_argument('--epochs', type=int, default=3,
                       help='Number of training epochs')
    parser.add_argument('--batch-size', type=int, default=4,
                       help='Training batch size')

    args = parser.parse_args()

    # Run pipeline
    main()